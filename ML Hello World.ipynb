{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mnist digit recognition is the very first algorithm to write for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/mnist_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/mnist_data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what was downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: mnist_data: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "%ls mnist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the data and see what's in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_digits,training_labels = mnist.train.next_batch(5000)\n",
    "test_digits, test_labels = mnist.test.next_batch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "(5000, 10)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] [[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(training_digits.shape)\n",
    "print(training_labels.shape)\n",
    "print(training_digits,training_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data will be used as inputs to the model , so let's create placeholders for them, as well as :\n",
    "1. Define the cost\n",
    "2. Create optimizer, that  minimizes this cost\n",
    "3. Batch up the training set and looping through it, while fitting the parameters W and b by running the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-01c32eb37cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/mnist_data/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\u001b[0m in \u001b[0;36mread_data_sets\u001b[0;34m(train_dir, fake_data, one_hot, dtype, reshape, validation_size, seed, source_url)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m   \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m   \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, images, labels, fake_data, one_hot, dtype, reshape, seed)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Convert from [0, 255] -> [0.0, 1.0].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate=0.01\n",
    "batch_size=100\n",
    "display_step = 1\n",
    "mnist = input_data.read_data_sets('data/mnist_data/',one_hot=True)\n",
    "\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[None,784], name='X')\n",
    "Y=tf.placeholder(dtype=tf.float32,shape=[None,10], name='Y')\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]),name='W')\n",
    "b= tf.Variable(tf.zeros([10]),name='b')\n",
    "\n",
    "\n",
    "Z=tf.matmul(X,W) +b\n",
    "A=tf.nn.softmax(Z)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(A), axis=-1))\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_index=0\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, batch_cost = sess.run([train_step, cost], feed_dict={X:batch_xs,Y:batch_ys}) \n",
    "        batch_index +=1\n",
    "        #print(\"Batch:\", '%04d' % (batch_index), \"cost=\", \"{:.9f}\".format(batch_cost))                        \n",
    "    print(\"Optimization Finished!\")     \n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(A, 1), tf.argmax(Y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    print(\"Train Accuracy:\", accuracy.eval({X: mnist.train.images, Y: mnist.train.labels}))\n",
    "    print(\"Test Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "    image=mnist.train.images[600]\n",
    "    result=sess.run(tf.argmax(A,axis=1),feed_dict={X:image.reshape(1,784)})\n",
    "    print(\"The recognized digit is {}\".format(result))\n",
    "    plt.imshow(image.reshape(28,28))\n",
    "    \n",
    "writer = tf.summary.FileWriter('./tbout/mnist1',sess.graph)\n",
    "writer.close()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Cost Function\n",
    "\n",
    "We've got to abandon the Mean Squared cost function because it slows down learning. We want a cost function that that learns quickly when the model is a lot wrong and slows down when the model is not that wrong\n",
    "\n",
    "Here's the best explaination for this - \n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function\n",
    "\n",
    "Entropy - disorder, uncertainty. If there is no uncertainty there is no information, e.g. if it always is sunny, if the weather forecast says it's sunny - there is not much information gained from it. \n",
    "    \n",
    "    `Entropy = amount of information.`  \n",
    " \n",
    "\n",
    "\n",
    "E.g. \n",
    "\n",
    "Assuming a known distribution of AB - 100% A and 0% B, how much information do you get when I tell you it's A?\n",
    "    \n",
    "    You've always know it'll be A because the distribution is 100% A, so it's not a surprise it's A, therefore you get 0 bit of information\n",
    "    \n",
    "    \n",
    "Assuming a known distribution of AB - 50% A and 50% B, how much information do you get when I tell you it's A?\n",
    "    \n",
    "    It could have be A or B - if I predicted it I could only gotten it right half the time - I've got to ask one question before I am certain ( is it A or B ). So I've got 1 bit of information \n",
    "        \n",
    "    \n",
    "Assuming a known distribution of ABC&D - 25% of A, 25% of B, 25% of C and 25% D, \n",
    "    \n",
    "    I could only have get a right outcome for sure after 2 questions, e.g. \n",
    "    \n",
    "    1-Is it A or B? \n",
    "        Yes - is it A? \n",
    "              Yes - it's A \n",
    "              No - it's B\n",
    "        No - is it C?\n",
    "             Yes - it's C\n",
    "             No - it's D\n",
    "             \n",
    "    I get 2 bit of information.\n",
    "    \n",
    "Assuming a know weather distribution of 75% sunny and 25% rainy,\n",
    "\n",
    "    When it's forecasted that it's going to rain tomorrow, my uncertainty has been reduced by a factor of 4(1/0.25) or I get 2 bit of information also give by log2 4 or -log2 p\n",
    "  \n",
    "What is the amount information you'll get from the weather forecast on average ?\n",
    "\n",
    "    -0.25*log2(0.25)-0.75log2(0.75)=0.81\n",
    "\n",
    "This is entropy, in general the entropy is, \n",
    "    \n",
    "    `H(p)=-np.sum(p*np.log2(p))`\n",
    "\n",
    "It's a measure of average information received or the unpredictability of the probablity distribution\n",
    "\n",
    "Cross entropy refers to the entropy calculated using the true distribution and the predicted distribution :\n",
    "\n",
    "    `H(p,q)=-np.sum(p*np.log2(q))` - p - true distribution and q - predicted distribution\n",
    "    \n",
    "https://www.youtube.com/watch?v=ErfnhcEV1O8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the parameters ( variables in tensorflow )\n",
    "\n",
    "We'd want to be able to save the parameters and then use them for predictions, so let's train the model and save it here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf4bd8b2e139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/mnist_data/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\u001b[0m in \u001b[0;36mread_data_sets\u001b[0;34m(train_dir, fake_data, one_hot, dtype, reshape, validation_size, seed, source_url)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m   \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m   \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, images, labels, fake_data, one_hot, dtype, reshape, seed)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Convert from [0, 255] -> [0.0, 1.0].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "learning_rate=0.01\n",
    "batch_size=100\n",
    "display_step = 1\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[None,784], name='X')\n",
    "Y=tf.placeholder(dtype=tf.float32,shape=[None,10], name='Y')\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]),name='W')\n",
    "b= tf.Variable(tf.zeros([10]),name='b')\n",
    "\n",
    "Z=tf.matmul(X,W) +b\n",
    "A=tf.nn.softmax(Z)\n",
    "mnist = input_data.read_data_sets('data/mnist_data/',one_hot=True)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(A), axis=-1))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_index=0\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, batch_cost = sess.run([train_step, cost], feed_dict={X:batch_xs,Y:batch_ys}) \n",
    "        batch_index +=1\n",
    "        #print(\"Batch:\", '%04d' % (batch_index), \"cost=\", \"{:.9f}\".format(batch_cost))                        \n",
    "            \n",
    "    print(\"Optimization Finished!\")     \n",
    "   \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(A, 1), tf.argmax(Y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    print(\"Train Accuracy:\", accuracy.eval({X: mnist.train.images, Y: mnist.train.labels}))\n",
    "    print(\"Test Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    saver = tf.train.Saver() \n",
    "    model_path=saver.save(sess, \"./tbout/models/model.ckpt\")\n",
    "    print ( 'Saving model to {}'.format(model_path) )\n",
    "    \n",
    "writer = tf.summary.FileWriter('./tbout/mnist2',sess.graph)\n",
    "writer.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's retrieve it and use it for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tbout/models/model.ckpt\n",
      "[-0.03748076  0.08087784 -0.01937952 -0.0207708   0.01952291  0.02983976\n",
      " -0.01153679  0.03211228 -0.06757122 -0.00561367]\n",
      "The recognized digit is [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADxJJREFUeJzt3X+wVPV5x/HPw+UCelUCSUCCUAyCRR2F9A6aYDMQa0aTVMykWqmNdBoDTSVTRiepodOEzOjU+rNqjCMqATuKEn/SKTVQYodkdAgXEwUlRHQoUu4AFh3QRITL0z/uIb3A3e8uu2f37PV5v2aY3T3POXue2eFzz+5+z56vubsAxNOv6AYAFIPwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iqn8jdzbABvogtTVyl0Ao7+s9feD7rJJ1awq/mV0k6U5JLZIecPebUusPUpvOtQtq2SWAhDW+quJ1q37bb2Ytku6RdLGkMyTNMLMzqn0+AI1Vy2f+yZI2u/sb7v6BpEclTc+nLQD1Vkv4R0p6s8fjbdmyw5jZLDPrMLOO/dpXw+4A5KmW8Pf2pcJRvw929wXu3u7u7a0aWMPuAOSplvBvkzSqx+NTJG2vrR0AjVJL+NdKGmdmp5rZAElXSFqWT1sA6q3qoT53P2BmcyT9RN1DfQvd/ZXcOgNQVzWN87v7cknLc+oFQANxei8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTV0im7gmFh6puldf3Nesv722V1V73rcQ+mp5fqtTV+l3g8cqHrfjcKRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqmmc38y2SNorqUvSAXdvz6MpxNAyfFiy/vpdJyfrG87/QZ7tHO6SdPmcH34zWR914/M5NlMfeZzkM83d38rheQA0EG/7gaBqDb9LWmFm68xsVh4NAWiMWt/2T3H37WY2TNJKM/u1u6/uuUL2R2GWJA3S8TXuDkBeajryu/v27HanpKckTe5lnQXu3u7u7a0aWMvuAOSo6vCbWZuZnXjovqTPS9qQV2MA6quWt/3DJT1l3T+77C/pEXd/NpeuANRd1eF39zcknZNjL/gQ2nnNZ0rWLpu9KrntMx/9j7zbyc13r1qSrC9a/oVk3X+Zvh5AIzDUBwRF+IGgCD8QFOEHgiL8QFCEHwiKS3cjqf/Jw5P1rfd+NFn/9z+6uWRtRMtxVfV0yD3vjE3W73+49HBbV5mTTddffXey/pUT0j9k/c7X25L18X+b3n8jcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5/+Q65r2qWR9+/mDkvVvX/l4sn7liZ1lOqh+LP+3/kGy/uPvX5Ssn7K09OWz/dPpX6O/fFV6eu+zB7Qk630BR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/j7Ap0xM1nd8a1/J2pOT7kpuO7p/bb+pr6dpN1ybrH986QtVP7e98FKy/ujb5ybrZw/vSNZ/8sU7kvVvakqy3ggc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqLLj/Ga2UNKXJO1097OyZUMlPSZpjKQtki5397fr1+aH265vfDpZXzHv1mR9cL/Ub/LrO45f7jf3+/1gydo/dP5JctthD6xN1j1ZLdap/dPXSWgGlRz5F0k68qoJ10ta5e7jJK3KHgPoQ8qG391XS9p9xOLpkhZn9xdLujTnvgDUWbWf+Ye7e6ckZbfD8msJQCPU/dx+M5slaZYkDdLx9d4dgApVe+TfYWYjJCm73VlqRXdf4O7t7t7eqjKzIwJomGrDv0zSzOz+TEnP5NMOgEYpG34zWyLpBUmnm9k2M/uapJskXWhmr0m6MHsMoA8p+5nf3WeUKF2Qcy99Vrk57F//Rnoe+UVfTc8Fnx7Hr6+N+/cn63OvnpOst/7nukT1d1V0hLxwhh8QFOEHgiL8QFCEHwiK8ANBEX4gKC7dXaH+Y0aXrP31iv9KbntJ2/Kcu8nPqt+lT7m+64t/mqy3bkoN5TWvlo8MTtaHDdjWoE6Kw5EfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL9Cr80eWbJ2SVvzXrV86bvpyyve+K9/nqyP2vR8nu00je1XnZmszx3y05qe/49fSr+ug7W5pufPA0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf5Mv0Hpy2Of8Zk3GtRJvm5Ykh5vHn3Dh3McX5JsUumx/Ieuvb3M1q017XvHlqHJevpqAo3BkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgio7zm9mCyV9SdJOdz8rWzZf0tcl7cpWm+fuzXtx+gq8/t1Jyforp/2gQZ0cu+/vmliy9sn70ucnHMi7mQZqGTIkWT942zslaxNaaxvH/9GeUcn6hLvT13joqmnv+ajkyL9I0kW9LL/D3Sdm//p08IGIyobf3VdL2t2AXgA0UC2f+eeY2ctmttDM0u+/ADSdasN/r6SxkiZK6pR0W6kVzWyWmXWYWcd+7atydwDyVlX43X2Hu3e5+0FJ90uanFh3gbu3u3t7qwZW2yeAnFUVfjMb0ePhlyVtyKcdAI1SyVDfEklTJX3MzLZJ+p6kqWY2UZJL2iJpdh17BFAHZcPv7jN6WfxgHXop1E//8pYyaxzXkD6q8cvpY0rWDnS+2bhGclbuGgsDnh6QrP/4tGV5tnOYu390abL+iY3Nf50EzvADgiL8QFCEHwiK8ANBEX4gKMIPBMWluzMjWo5P1g/KG9TJ0cY/mz6NYvzWdQ3q5Ni1nHRSydrmeelpsp+/8tZkfXC/9FBgyj7fn6xPvu/aZH3ULS9Uve9mwZEfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinD/TYum/gwe9uIstT7i59CWoJanLqz8Hof/ITyTr750zMlnfekX6dXn6sz8sWZvQ+lxyW6n6cXxJuuedsSVrj9xycXLbUYua/ye5teLIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc6fueDVS5L1Zyc81aBOjvbbu9MTae95//Sqn/vbp69I1r9ywltVP3e36qfCXv1++tLcV6/8WrI+4a7S50cMebXv/x6/Vhz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCosuP8ZjZK0kOSTpZ0UNICd7/TzIZKekzSGElbJF3u7m/Xr9X66jd/aLL+3KLSvy2fdtz7ebdzmJVnPlHX56+n6zrPK1n7t19MSm77h/ftTdbHv/SLZL24KzD0DZUc+Q9Ius7dJ0g6T9I1ZnaGpOslrXL3cZJWZY8B9BFlw+/une7+YnZ/r6SNkkZKmi5pcbbaYkmX1qtJAPk7ps/8ZjZG0iRJayQNd/dOqfsPhKRheTcHoH4qDr+ZnSDpCUlz3X3PMWw3y8w6zKxjv/ZV0yOAOqgo/GbWqu7gP+zuT2aLd5jZiKw+QtLO3rZ19wXu3u7u7a0amEfPAHJQNvxmZpIelLTR3W/vUVomaWZ2f6akZ/JvD0C9mJe57LOZnS/pZ5LWq3uoT5Lmqftz/1JJoyVtlXSZu+9OPddJNtTPtQtq7bkQLWeW/tnspu+kp/f+9bQH8m7nMPsTlxX/3Mt/UdNz7+j8SLJ+6pL0/5+Ba35TsnZwb3ooD8duja/SHt9tlaxbdpzf3X8uqdST9c0kA+AMPyAqwg8ERfiBoAg/EBThB4Ii/EBQXLq7Ql2vbCpZGz+7LbnthPlzkvXH/uzOZP3sAS3J+pR/mluyNuye2qaaHlzT1v9/YgiaD0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf4cHHzvvWR97LfS00H/4z9fnKzvmXpasr73vNKj6VxYEaVw5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnbwJdb/1vst72eLo+9vE8u0EUHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiy4TezUWb2nJltNLNXzOzvsuXzzex/zOxX2b8v1L9dAHmp5CSfA5Kuc/cXzexESevMbGVWu8Pdb61fewDqpWz43b1TUmd2f6+ZbZQ0st6NAaivY/rMb2ZjJE2StCZbNMfMXjazhWY2pMQ2s8ysw8w69mtfTc0CyE/F4TezEyQ9IWmuu++RdK+ksZImqvudwW29befuC9y93d3bWzUwh5YB5KGi8JtZq7qD/7C7PylJ7r7D3bvc/aCk+yVNrl+bAPJWybf9JulBSRvd/fYey0f0WO3Lkjbk3x6Aeqnk2/4pkr4qab2Z/SpbNk/SDDObKMklbZE0uy4dAqiLSr7t/7kk66W0PP92ADQKZ/gBQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCMndv3M7Mdkn67x6LPibprYY1cGyatbdm7Uuit2rl2dsfuPvHK1mxoeE/audmHe7eXlgDCc3aW7P2JdFbtYrqjbf9QFCEHwiq6PAvKHj/Kc3aW7P2JdFbtQrprdDP/ACKU/SRH0BBCgm/mV1kZpvMbLOZXV9ED6WY2RYzW5/NPNxRcC8LzWynmW3osWyoma00s9ey216nSSuot6aYuTkxs3Shr12zzXjd8Lf9ZtYi6TeSLpS0TdJaSTPc/dWGNlKCmW2R1O7uhY8Jm9lnJb0r6SF3PytbdrOk3e5+U/aHc4i7/32T9DZf0rtFz9ycTSgzoufM0pIulfRXKvC1S/R1uQp43Yo48k+WtNnd33D3DyQ9Kml6AX00PXdfLWn3EYunS1qc3V+s7v88DVeit6bg7p3u/mJ2f6+kQzNLF/raJfoqRBHhHynpzR6Pt6m5pvx2SSvMbJ2ZzSq6mV4Mz6ZNPzR9+rCC+zlS2ZmbG+mImaWb5rWrZsbrvBUR/t5m/2mmIYcp7v4pSRdLuiZ7e4vKVDRzc6P0MrN0U6h2xuu8FRH+bZJG9Xh8iqTtBfTRK3ffnt3ulPSUmm/24R2HJknNbncW3M/vNdPMzb3NLK0meO2aacbrIsK/VtI4MzvVzAZIukLSsgL6OIqZtWVfxMjM2iR9Xs03+/AySTOz+zMlPVNgL4dplpmbS80srYJfu2ab8bqQk3yyoYx/kdQiaaG739jwJnphZp9U99Fe6p7E9JEiezOzJZKmqvtXXzskfU/S05KWShotaauky9y94V+8lehtqrrfuv5+5uZDn7Eb3Nv5kn4mab2kg9nieer+fF3Ya5foa4YKeN04ww8IijP8gKAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E9X8k3hIErnQQXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "W = tf.get_variable(\"W\", shape=[784,10])\n",
    "b = tf.get_variable(\"b\", shape=[10])\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[None,784], name='X')\n",
    "Y=tf.placeholder(dtype=tf.float32,shape=[None,10], name='Y')\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver() \n",
    "    saver.restore(sess, \"./tbout/models/model.ckpt\")\n",
    "\n",
    "    print(b.eval())\n",
    "\n",
    "    Z=tf.matmul(X,W) +b\n",
    "    A=tf.nn.softmax(Z)\n",
    "\n",
    "    image=mnist.train.images[600]\n",
    "    result=sess.run(tf.argmax(A,axis=1),feed_dict={X:image.reshape(1,784)})\n",
    "    print(\"The recognized digit is {}\".format(result))\n",
    "    plt.imshow(image.reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
